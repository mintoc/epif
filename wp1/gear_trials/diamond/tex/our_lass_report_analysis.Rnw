%% knit("our_lass_report_analysis.Rnw")

\documentclass[12pt]{article}
\usepackage{times}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage{fullpage}
\usepackage{pdflscape}
\hypersetup{pdfpagemode=UseNone} % don't show bookmarks on initial view
\hypersetup{colorlinks, urlcolor={blue}}

% revise margins
\setlength{\headheight}{0.0in}
\setlength{\topmargin}{0.0in}
\setlength{\headsep}{0.0in}
\setlength{\textheight}{8.65in}
\setlength{\footskip}{0.35in}
\setlength{\oddsidemargin}{0.0in}
\setlength{\evensidemargin}{0.0in}
\setlength{\textwidth}{6.5in}

\setlength{\parskip}{6pt}
\setlength{\parindent}{0pt}

\title{\emph{Our Lass} 70mm versus 80mm analysis}
\author{For discussion}
\date{}

\begin{document}

<<echo=FALSE>>=
library(knitr)
opts_chunk$set(size="footnotesize")
## set the working directory
##setwd('../tex'); 
@

\maketitle

\section{Data}

Read the data in and make a few factor variables
<<eval = TRUE>>=
library(gdata)
library(reshape)

neph.dat <- read.xls("../data/2015 BIM Nephrops quad rig trials/Our Lass 2 70_80_90_100mm codends Irish Sea July 2015/Nephrops Raised Counts Our Lass 2 Irish Sea July 2015.xlsx",
                     sheet = "All hauls",
                     stringsAsFactors = FALSE)

## subset containing the 70mm and 80mm data
neph.7080 <- subset(neph.dat, Mesh.Size %in% c("70mm", "80mm"))

## make factor haul variable
neph.7080$fHAUL <- factor(paste("H", neph.7080$Haul.No, sep =""))

## make a factor mesh size variable
neph.7080$fMesh.Size <- factor(paste("mesh", neph.7080$Mesh.Size, sep = ""))

## remove trailing dot from raised count column name
names(neph.7080)[names(neph.7080) == "Raised.count."] <- "Raised.count"

@ 

Re-shape the data to wide format (columns for 70mm, 80mm variables).
<<eval = TRUE>>=
## get count per length bin per haul by mesh size
## using the reshape package (makes it easier to process data)
library(reshape)

## variables to keep 
vars2keep <- c("fHAUL", "fMesh.Size", "Net.position", "Carapace.length", 
               "Count", "Raised.count", "Total.catch", "Overall.Sampling.Ratio")

## melt the data frame
neph.7080.melt <- melt(neph.7080[, vars2keep], 
                           id = c("fHAUL", "fMesh.Size", "Carapace.length"))

## re-form the dataframe in required format 
neph.7080.cast <- cast(neph.7080.melt, Carapace.length + fHAUL ~ fMesh.Size  + variable)

## first couple of lines
head(neph.7080.cast, 2)

summary(neph.7080.cast) ## note lots of NAs

## fill in missing values 
## these occur if there is a count for e.g. 20mm CL in 70mm but not in 80mm
neph.7080.cast$mesh70mm_Count[is.na(neph.7080.cast$mesh70mm_Count)] <- 0
neph.7080.cast$mesh70mm_Raised.count[is.na(neph.7080.cast$mesh70mm_Raised.count)] <- 0
neph.7080.cast$mesh80mm_Count[is.na(neph.7080.cast$mesh80mm_Count)] <- 0
neph.7080.cast$mesh80mm_Raised.count[is.na(neph.7080.cast$mesh80mm_Raised.count)] <- 0

for(i in 1:dim(neph.7080.cast)[1]){
  haul.dat <- subset(neph.7080.cast, fHAUL == neph.7080.cast$fHAUL[i])
  ## 70mm net position
  if(is.na(neph.7080.cast$mesh70mm_Net.position[i])){
    neph.7080.cast$mesh70mm_Net.position[i] <-
      unique(na.omit(haul.dat$mesh70mm_Net.position))
  }
  ## 80mm net position
  if(is.na(neph.7080.cast$mesh80mm_Net.position[i])){
    neph.7080.cast$mesh80mm_Net.position[i] <-
      unique(na.omit(haul.dat$mesh80mm_Net.position))
  }
  ## 70mm total catch
  if(is.na(neph.7080.cast$mesh70mm_Total.catch[i])){
    neph.7080.cast$mesh70mm_Total.catch[i] <-
      unique(na.omit(haul.dat$mesh70mm_Total.catch))
  }
  ## 80mm total catch
  if(is.na(neph.7080.cast$mesh80mm_Total.catch[i])){
    neph.7080.cast$mesh80mm_Total.catch[i] <-
      unique(na.omit(haul.dat$mesh80mm_Total.catch))
  }
  ## Sampling ratio
  ## 70mm total catch
  if(is.na(neph.7080.cast$mesh70mm_Overall.Sampling.Ratio[i])){
    neph.7080.cast$mesh70mm_Overall.Sampling.Ratio[i] <-
      unique(na.omit(haul.dat$mesh70mm_Overall.Sampling.Ratio))
  }
  ## 80mm total catch
  if(is.na(neph.7080.cast$mesh80mm_Overall.Sampling.Ratio[i])){
    neph.7080.cast$mesh80mm_Overall.Sampling.Ratio[i] <-
      unique(na.omit(haul.dat$mesh80mm_Overall.Sampling.Ratio))
  }
}

summary(neph.7080.cast) ## no missing

@ 

Get the empirical proportion 80/(70 + 80) at length. Note that the length-specific CIs do not reflect the non-independence of the observations across lengths at the haul level are therefore not plotted. 
<<>>=
## vector of carapace lengths
cl.vec <- unique(neph.7080.cast$Carapace.length)
cl.vec <- cl.vec[order(cl.vec)]

## including number of observations contributing to count here
count.df <- data.frame(Carapace.length = cl.vec, N = NA, prop.80 = NA)

for(i in 1:dim(count.df)[1]){
  sub.dat <- subset(neph.7080.cast, Carapace.length == count.df$Carapace.length[i])
  ##
  if(dim(sub.dat)[1] > 1){
    ## raised number
    count.df$N[i] <- with(sub.dat,  
                          round(sum(mesh80mm_Raised.count)) + round(sum(mesh70mm_Raised.count)))
    ##
    count.df$prop.80[i] <- with(sub.dat, round(sum(mesh80mm_Raised.count)) / 
                                (round(sum(mesh80mm_Raised.count)) + round(sum(mesh70mm_Raised.count))))
    rm(list = c("sub.dat"))
  }
}

@ 

Plot the data (Figure~\ref{fig:rawprops})
<<rawprops, eval = TRUE, fig.allign = "center", fig.cap = "Proportion of Nephrops raised numbers retained in the 80mm over the sum of the 80mm and 70mm meshes.", fig.width = 6, fig.height = 5>>=

with(count.df, plot(Carapace.length, prop.80, ylim = c(0, 1), pch = 19,
                    xlab = "Carapace length (mm)", 
                    ylab = "Proportion (N80mm/(N70mm + N80mm))",
                    bty = "L", 
                    cex = 1/5 * log(N)))
abline(h = 0.5, lty = 2)

@

\section{Models}
A catch comparison binomial Generalized Additive/Linear Mixed Model is suitable choice for these count data where we are interested in estimating how the proportion changes with carapace length. We first try a model with only carapace length as an explanatory variable with haul random effects.

<<>>=
library(mgcv)

neph.7080.cast$dum <- 1

## no length effect
gamm.null <- gam(cbind(mesh80mm_Count, mesh70mm_Count) ~ 1 +
                 s(fHAUL, bs="re", by = dum),
                 offset = 
                 log(mesh80mm_Overall.Sampling.Ratio / 
                     mesh70mm_Overall.Sampling.Ratio),
                 family = binomial,
                 data = neph.7080.cast)

gamm.alt <- gam(cbind(mesh80mm_Count, mesh70mm_Count) ~ 
                s(Carapace.length, k = 5) +
                s(fHAUL, bs="re", by = dum),
                offset = 
                log(mesh80mm_Overall.Sampling.Ratio / 
                    mesh70mm_Overall.Sampling.Ratio),
                family = binomial,
                data = neph.7080.cast)

## likelihood ratio test for the significance of carapace length
anova(gamm.null, gamm.alt, test = "Chisq")

@ 

Plot the predictions from this model.

<<glmmsimple, eval = TRUE, fig.allign = "center", fig.cap = "Predicted proportion from binomial GLMM without covariates.", fig.width = 6, fig.height = 5>>=

mean.catch <- mean(c(unique(neph.7080.cast$mesh70mm_Total.catch),
                     unique(neph.7080.cast$mesh80mm_Total.catch)))

## data frame to predictfor
pred.df <- data.frame(Carapace.length = cl.vec,
                      fHAUL = "H1",
                      dum = 0,
                      mesh80mm_Overall.Sampling.Ratio = 1,
                      mesh70mm_Overall.Sampling.Ratio = 1,
                      mesh70mm_Total.catch = mean.catch,
                      mesh80mm_Total.catch = mean.catch
                      )

pred.gamm.alt <- predict(gamm.alt, newdata = pred.df, se.fit = TRUE)

## predicted proportions and confidence intervals
pred.df$pred.prop <- plogis(pred.gamm.alt$fit)
pred.df$lwr.prop <- plogis(pred.gamm.alt$fit - qnorm(0.975) * pred.gamm.alt$se.fit)
pred.df$upr.prop <- plogis(pred.gamm.alt$fit + qnorm(0.975) * pred.gamm.alt$se.fit)


with(count.df, plot(Carapace.length, prop.80, ylim = c(0, 1), pch = 19,
                    xlab = "Carapace length (mm)", 
                    ylab = "Proportion (N80mm/(N70mm + N80mm))",
                    bty = "L",
                    cex = 1/5 * log(N)))

with(pred.df, lines(Carapace.length, pred.prop))
with(pred.df, lines(Carapace.length, lwr.prop, lty = 2))
with(pred.df, lines(Carapace.length, upr.prop, lty = 2))
abline(h = 0.5, col = "slategrey")

@ 

The cause of the wide confidence intervals (Figure ~ \ref{fig:glmmsimple}) is the large amount of inter-haul variability in the proportion retained in the 80mm (Figure~\ref{fig:haulprop})

<<haulprop, eval = TRUE, fig.allign = "center", fig.cap = "Observed proportion in the 80mm by haul. Note the wide variability of the proportion with some having much higher or lower proportions. Fitted lines come from the GLMM with carapace length only.", fig.width = 6, fig.height = 5>>=

## Get the proportion at length by haul
haul.count.df <- expand.grid(Carapace.length = cl.vec, 
                             fHAUL = unique(neph.7080.cast$fHAUL))

## order the levels
haul.count.df$fHAUL <- factor(as.character(haul.count.df$fHAUL), 
                              levels = c(paste("H", 1:12, sep = ""), "H14"))
                            
haul.count.df$prop.80 <- NA
haul.count.df$N <- NA
haul.count.df$lwr <- NA
haul.count.df$upr <- NA

for(i in 1:dim(haul.count.df)[1]){
  sub.dat <- subset(neph.7080.cast, 
                    Carapace.length == haul.count.df$Carapace.length[i] & 
                    fHAUL == haul.count.df$fHAUL[i])
  ##
  ##if((sub.dat$mesh80mm_Raised.count + sub.dat$mesh70mm_Raised.count) > 0){
  if(dim(sub.dat)[1] > 0){
    btest <- with(sub.dat, 
                  binom.test(x = round(mesh80mm_Raised.count),
                             n = round(mesh80mm_Raised.count + mesh70mm_Raised.count)))
    ##
    haul.count.df$N[i] <- with(sub.dat, 
                               round(mesh80mm_Raised.count + mesh70mm_Raised.count))
    haul.count.df$prop.80[i] <- btest$estimate
    haul.count.df$lwr[i] <- btest$conf.int[1]
    haul.count.df$upr[i] <- btest$conf.int[2]
    ##
    rm(list = c("sub.dat", "btest"))
  }
}

## get predictions at the HAUL level from model
haul.count.df$dum <- 1
haul.count.df$pred.prop <- plogis(predict(gamm.alt, newdata = haul.count.df))


library(ggplot2)

blue2red <- colorRampPalette(c("darkblue", "white", "red"))

ggplot(haul.count.df, aes(x = Carapace.length, y = prop.80)) +
  geom_point(aes(colour = fHAUL, size = 1/5 * log(N))) + 
  geom_line(data = haul.count.df, aes(x = Carapace.length, y = pred.prop,  colour = fHAUL)) +
  scale_colour_manual(values = blue2red(13)) + ylab("Proportion in 80mm")

@ 

We can take a look at additional measured covariates to see if these relate to the haul-level variability (random effects in the model above) (Figure~\ref{fig:ranefplots}). Firstly, read in the haul duration data

<<>>=
gear.details <- read.xls("../data/2015 BIM Nephrops quad rig trials/Our Lass 2 70_80_90_100mm codends Irish Sea July 2015/Irish Sea data.xlsx", sheet = 2)

## merge with the neph data 
gear.details$fHAUL <- factor(paste("H", gear.details$Tow.., sep = ""))

tmp <- strsplit(as.character(gear.details$Tow.duration), split = ":")

hr <- as.numeric(unlist(lapply(tmp, "[", 1)))
min <- as.numeric(unlist(lapply(tmp, "[", 2)))

gear.details$dec.hr <- hr + min / 60

@ 


<<ranefplots, eval = TRUE, fig.allign = "center", fig.cap = "Relationship between the random effects of the carapace length only model and measured covariates .", fig.width = 6, fig.height = 5, warnings = FALSE>>=
##
ranef.df <- data.frame(fHAUL = levels(neph.7080.cast$fHAUL),
                       ranef = coef(gamm.alt)[-c(1:5)])
##
covar.names <- c("fHAUL", "mesh70mm_Net.position", "mesh70mm_Total.catch", 
                 "mesh80mm_Net.position", "mesh80mm_Total.catch")
##
covar.df <- unique(neph.7080.cast[, covar.names])
## include haul duration
covar.df <- merge(covar.df, gear.details[, c("fHAUL", "dec.hr")])
##
ranef.df <- merge(ranef.df, covar.df)
## convert to long format for plotting
ranef.df <- melt(ranef.df, id = c("fHAUL", "ranef"))

##
ggplot(ranef.df, aes(x = value, y = ranef)) + 
  geom_point() + 
  facet_wrap(~ variable, scales = "free") +
  xlab("Covariate value") +
  ylab("Random effect")

@

There are some strong relationships between the random effects and measured covariates (Figure~\ref{fig:ranefplots}). It is best to include these measured variables in the model as fixed effects.

<<>>=
library(lme4)
library(effects)

## including additional covariates
## check identifiability
neph.7080.cast$fmesh80mm_Net.position <- 
  factor(paste("pos", 
               neph.7080.cast$mesh80mm_Net.position, sep = ""))

neph.7080.cast <- merge(neph.7080.cast, gear.details[, c("fHAUL", "dec.hr")])

## using log of total catch weights - return to this
neph.7080.cast$log.mesh80mm_Total.catch <- log(neph.7080.cast$mesh80mm_Total.catch)
neph.7080.cast$log.mesh70mm_Total.catch <- log(neph.7080.cast$mesh70mm_Total.catch)

max.Carapace.length <- max(neph.7080.cast$Carapace.length)
neph.7080.cast$prop.Carapace.length <- neph.7080.cast$Carapace.length / max.Carapace.length

## Note should return to this warning later
## fits okay in gam but glmm used for effects package
glmm.alt.covar <- glmer(cbind(mesh80mm_Count, mesh70mm_Count) ~ 
                        ##I(log(mesh80mm_Total.catch / mesh70mm_Total.catch)) * Carapace.length +
                        log.mesh80mm_Total.catch + log.mesh70mm_Total.catch + 
                        prop.Carapace.length +
                        fmesh80mm_Net.position +
                        (1 | fHAUL),
                        offset = 
                        log(mesh80mm_Overall.Sampling.Ratio / 
                            mesh70mm_Overall.Sampling.Ratio),
                        family = binomial,
                        data = neph.7080.cast,
                        control=glmerControl(optimizer="bobyqa"))

glmm.alt.covar.catchdur <- glmer(cbind(mesh80mm_Count, mesh70mm_Count) ~ 
                                 ##I(log(mesh80mm_Total.catch / mesh70mm_Total.catch)) * Carapace.length +
                                 log.mesh80mm_Total.catch + log.mesh70mm_Total.catch + 
                                 prop.Carapace.length +
                                 fmesh80mm_Net.position +
                                 poly(dec.hr, 1) +
                                 (1 | fHAUL),
                                 offset = 
                                 log(mesh80mm_Overall.Sampling.Ratio / 
                                     mesh70mm_Overall.Sampling.Ratio),
                                 family = binomial,
                                 data = neph.7080.cast,
                                 control=glmerControl(optimizer="bobyqa"))

glmm.alt.covar.catchdur.nobulk <- glmer(cbind(mesh80mm_Count, mesh70mm_Count) ~ 
                                        ##I(log(mesh80mm_Total.catch / mesh70mm_Total.catch)) * Carapace.length +
                                        ##log.mesh80mm_Total.catch + log.mesh70mm_Total.catch + 
                                        prop.Carapace.length +
                                        fmesh80mm_Net.position +
                                        poly(dec.hr, 1) +
                                        (1 | fHAUL),
                                        offset = 
                                        log(mesh80mm_Overall.Sampling.Ratio / 
                                            mesh70mm_Overall.Sampling.Ratio),
                                        family = binomial,
                                        data = neph.7080.cast,
                                        control=glmerControl(optimizer="bobyqa"))

## include squared length term
glmm.alt.covar2 <- glmer(cbind(mesh80mm_Count, mesh70mm_Count) ~ 
                         ##I(log(mesh80mm_Total.catch / mesh70mm_Total.catch)) * Carapace.length +
                         log.mesh80mm_Total.catch + log.mesh70mm_Total.catch + 
                         poly(prop.Carapace.length, 2) +
                         poly(dec.hr, 1) +
                         fmesh80mm_Net.position +
                         (1 | fHAUL),
                         offset = 
                         log(mesh80mm_Overall.Sampling.Ratio / 
                             mesh70mm_Overall.Sampling.Ratio),
                         family = binomial,
                         data = neph.7080.cast,
                         control=glmerControl(optimizer="bobyqa"))

## in GAM
gamm.alt.covar2 <- gam(cbind(mesh80mm_Count, mesh70mm_Count) ~ 
                       ##I(log(mesh80mm_Total.catch / mesh70mm_Total.catch)) * Carapace.length +
                       log.mesh80mm_Total.catch + log.mesh70mm_Total.catch + 
                       s(prop.Carapace.length, k = 5, fx = TRUE) +
                       poly(dec.hr, 1) +
                       fmesh80mm_Net.position +
                       s(fHAUL, bs="re", by = dum),
                       offset = 
                       log(mesh80mm_Overall.Sampling.Ratio / 
                           mesh70mm_Overall.Sampling.Ratio),
                       family = binomial,
                       data = neph.7080.cast)

## use effects package to get prediction for model with net position
## set predictor variables
xlevels <- list(prop.Carapace.length = cl.vec/max.Carapace.length)

## if we wanted to set the proportions of net positions equivalent
## otherwise set to the proportion observed in the data
##given.values <- c("fmesh80mm_Net.positionpos2" = 1/4,
##                  "fmesh80mm_Net.positionpos3" = 1/4,
##                  "fmesh80mm_Net.positionpos4" = 1/4
##                  )

##cl.effect <- effect("Carapace.length", glmm.alt.covar, xlevels = xlevels, offset = 0, given.values = given.values)
cl.effect <- effect("prop.Carapace.length", glmm.alt.covar.catchdur, xlevels = xlevels, offset = 0)

@ 

Plot the effect of carapace length with the other variables set to their mean in the data (Figure~\ref{fig:glmmcovar}).

<<glmmcovar, eval = TRUE, fig.allign = "center", fig.cap = "Predicted proportion from binomial GLMM with covariates. Note in the predictions the bulk weights are set to their mean and the net positions to their proportional occurence in the data.", fig.width = 6, fig.height = 5, warnings = FALSE>>=

with(count.df, plot(Carapace.length, prop.80, ylim = c(0, 1), pch = 19,
                    xlab = "Carapace length (mm)", 
                    ylab = "Proportion (N80mm/(N70mm + N80mm))",
                    bty = "L",
                    cex = 1/5 * log(N)))

## effects prediction
lines(cl.vec, plogis(cl.effect$fit[, 1]))
lines(cl.vec, plogis(cl.effect$lower[, 1]), lty = 2)
lines(cl.vec, plogis(cl.effect$upper[, 1]), lty = 2)
abline(h = 0.5, col = "slategrey")

## Note the wide confidence intervals
@ 

Finally test length effect in covariate model
<<>>=

glmm.alt.covar.catchdur.nolength <- glmer(cbind(mesh80mm_Count, mesh70mm_Count) ~ 
                                          log.mesh80mm_Total.catch + log.mesh70mm_Total.catch + 
                                          fmesh80mm_Net.position +
                                          poly(dec.hr, 1) +
                                          (1 | fHAUL),
                                          offset = 
                                          log(mesh80mm_Overall.Sampling.Ratio / 
                                              mesh70mm_Overall.Sampling.Ratio),
                                          family = binomial,
                                          data = neph.7080.cast,
                                          control=glmerControl(optimizer="bobyqa"))

  
## likelihood ratio test
anova(glmm.alt.covar.catchdur.nolength, glmm.alt.covar.catchdur)
## significant effect of carapace length
@ 

\section{Economic section}

<<lw, eval = TRUE, fig.allign = "center", fig.cap = "Length - weight relationship with horizontal price bands converted to length-based price bands. Price band in black denotes below Minimum Conservation Reference Size prawns.", fig.width = 6, fig.height = 5, warnings = FALSE>>=

curve(0.00032 * x^3.21, from = 0, to = 60, xlab = "Carapace length (mm)", 
      ylab = "Total weight (g)")

npkilo.breaks <- c(1, 11, 16, 21, 31, 41, 50)
wt.breaks <- (1/ npkilo.breaks) * 1e3
abline(h = wt.breaks, col = "grey")

## corresponding length cut-offs
lt.breaks = exp(log(wt.breaks / 0.00032)/3.21)
abline(v = lt.breaks, col = "grey")

## below MCRS band
abline(v = 20)
abline(h = 0.00032*20^3.21)

@ 

Simulate distributions of retained catches with different means

<<>>=
sim.means <- c(24, 27, 33)

## get the vector of raised counts for the whole Our Lass trip
neph.lengths <- with(subset(neph.dat, Mesh.Size%in%c("70mm", "80mm")), 
                     rep(Carapace.length, times = round(Raised.count.)))

length(neph.lengths) ## raised number of prawns caught

(mean.cl <- mean(neph.lengths)) ## mean carapace length below

## differences in the mean observed length and simulated means
## plus 0.5 to account for nearest mm below
sim.diff <- mean.cl - (sim.means + 0.5)

@ 

<<simdist, eval = TRUE, fig.allign = "center", fig.cap = "Simulated distributions of retained catches.", fig.width = 8, fig.height = 7, warnings = FALSE>>=

## plot the simulated distributions of retained catches
hist.orig <- hist(neph.lengths, breaks = seq(0.5, 60, by = 1), plot = FALSE)
##hist.orig <- hist(neph.lengths, breaks = seq(1, 60, by = 1), plot = FALSE)
cl.mids <- hist.orig$mids
count.sim <- matrix(hist.orig$counts, nrow = 1)

plot(hist.orig$mids, hist.orig$counts, type = "l", xlim = c(10, 50),
     xlab = "Carapace length (mm)", ylab = "Count per 1 mm bin")
##
for(i in 1:length(sim.means)){
  hist.sim <- hist(neph.lengths - sim.diff[i], 
                   breaks = seq(0.5, 60, by = 1), plot = FALSE)
                   ##breaks = seq(1, 60, by = 1), plot = FALSE)
  lines(hist.sim$mids, hist.sim$counts, lty = 1 + i, col = 1+i)  
  count.sim <- rbind(count.sim, hist.sim$counts)
}

legend("topright", legend = 
       c("Original (30.09mm)", "24mm mean", 
         "27mm mean", "33mm mean"),
       lty = c(1:4), col = 1:4, bty = "n")
## 
rownames(count.sim) <- c("original", "mm.24", "mm.27", "mm.33")

@ 

Per-haul variables
<<>>=

## count per haul (13 hauls)
count.phaul.sim <- count.sim / (13) ## note this is the sum for the 70 and 80

## get predicted prawn weight per length bin in kgs
wt.mids <- (0.00032 * cl.mids^3.21) / 1e3

## get total weight per haul
wt.phaul.sim <- t(apply(count.phaul.sim, 1, FUN = function(z){z * wt.mids}))

## predicted price per length class 
## note 20mm CL included here
wt.cuts <- cut(wt.mids, breaks = c(wt.breaks, 0.00032*20^3.21, 0) / 1e3)

price.df <-  data.frame(wt.bin = unique(wt.cuts), 
                        price = c(-0.2, 1.90, 4.75, 5.35, 7.75, 10.75, 13, 13))

price.df

## prices per length class bin
price.bin.df <- merge(data.frame(wt.bin = wt.cuts), price.df)
price.bin.df$Carapace.length <- cl.mids

## value per haul
value.phaul.sim <- t(apply(wt.phaul.sim, 1, FUN = function(z){z * price.bin.df$price}))

@ 

Finally, split the variables at length between 70 and 80mm.

<<>>=
## get predicted proportions in 80mm for given carapace length mid-points
xlevels <- list(prop.Carapace.length = cl.mids/max.Carapace.length)

## set the proportions of net positions equivalent
given.values <- c("fmesh80mm_Net.positionpos2" = 1/4,
                  "fmesh80mm_Net.positionpos3" = 1/4,
                  "fmesh80mm_Net.positionpos4" = 1/4
                  )

cl.effect <- effect("prop.Carapace.length", glmm.alt.covar.catchdur, xlevels = xlevels, offset = 0, given.values = given.values)

p80 <- plogis(cl.effect$fit[, 1])

## plot(cl.mids, p80, ylim = c(0, 1))

## split out 70 and 80
## count
count.phaul.sim.80 <- t(apply(count.phaul.sim, 1, FUN = function(z){z * p80}))
count.phaul.sim.70 <- t(apply(count.phaul.sim, 1, FUN = function(z){z * (1 - p80)}))

## weight
wt.phaul.sim.80 <- t(apply(wt.phaul.sim, 1, FUN = function(z){z * p80}))
wt.phaul.sim.70 <- t(apply(wt.phaul.sim, 1, FUN = function(z){z * (1 - p80)}))

## value
value.phaul.sim.80 <- t(apply(value.phaul.sim, 1, FUN = function(z){z * p80}))
value.phaul.sim.70 <- t(apply(value.phaul.sim, 1, FUN = function(z){z * (1 - p80)}))

@ 

Plot the counts, weights and value per length bin split by 70 and 80mm (Figure~\ref{fig:split_plots}).

<<split_plots, eval = TRUE, fig.allign = "center", fig.cap = "Simulated counts, weight and value by: length class, mesh size and  simulated scenario (24mm mean catch, 27mm mean catch, 30mm mean catch (original), 33mm mean catch).", fig.width = 6, fig.height = 5>>=

par(mfrow = c(2, 2), mar = c(2, 3, 1, 1), oma = c(2, 2, 1, 1))
## Count
matplot(cl.mids, t(count.phaul.sim.80), 
        type = "l", col = "darkblue", 
        xlim = c(10, 50), ylim = c(0, 1e3))
matlines(cl.mids, t(count.phaul.sim.70), type = "l", col = "red1")
mtext(side = 2, line = 2, text = "Count per 1mm bin")
## to demonstrate same retention across scenarios
## use xlim = c(15, 40) and abline(v = c(23.3, 26.3, 29.3))
## Weight
matplot(cl.mids, t(wt.phaul.sim.80), 
        type = "l", col = "darkblue", 
        xlim = c(10, 50), ylim = c(0, 20))
matlines(cl.mids, t(wt.phaul.sim.70), type = "l", col = "red1")
mtext(side = 2, line = 2, text = "Weight (kg) per 1mm bin")
## Value
matplot(cl.mids, t(value.phaul.sim.80), 
        type = "l", col = "darkblue", 
        xlim = c(10, 50), ylim = c(0, 110))
matlines(cl.mids, t(value.phaul.sim.70), type = "l", col = "red1")
mtext(side = 2, line = 2, text = "Value (euro) per 1mm bin")
##
plot.new()
legend("center", legend = c("70mm", "80mm", NA, "Original (30.09mm)", "24mm mean", 
                   "27mm mean", "33mm mean"),
       lty = c(1,1,NA, 1:4),
       col = c("red1", "darkblue", NA, rep("darkblue", 4)),
       bty = "n"
       )

@ 

Summary table (as in BIM report Table 3)
<<>>=

## calculate the resulting mean sizes per length class
##apply(count.phaul.sim, 1, FUN = function(z){sum(cl.mids * z) / sum(z)})
mean.cl.70 <- apply(count.phaul.sim.70, 1, FUN = function(z){sum(cl.mids * z) / sum(z)})
mean.cl.80 <- apply(count.phaul.sim.80, 1, FUN = function(z){sum(cl.mids * z) / sum(z)})

## data frame for predictions
na.vec <- rep(NA, 8)
sim.order <- c("original", "mm.33", "mm.27", "mm.24")

pred.df <- data.frame(Mesh.Size = rep(c(70, 80), each = 4),
                      Mean.CL = rep(sim.order, 2),
                      Mean.CL.mesh = c(mean.cl.70[sim.order], mean.cl.80[sim.order]),
                      c.less.mcrs = na.vec,
                      c.greater.mcrs = na.vec,
                      total.catch = na.vec, 
                      v.less.mcrs = na.vec,
                      v.greater.mcrs = na.vec,
                      total.value = na.vec,
                      stringsAsFactors = FALSE)
##

for(i in 1:dim(pred.df)[1]){
  print(i)
  wt <- get(paste("wt.phaul.sim.", pred.df$Mesh.Size[i], sep = ""))
  value <- get(paste("value.phaul.sim.", pred.df$Mesh.Size[i], sep = ""))
  ## catch
  pred.df$c.less.mcrs[i] <- sum(wt[pred.df$Mean.CL[i], cl.mids < 20])
  pred.df$c.less.mcrs[i] <- round(pred.df$c.less.mcrs[i], 2)
  pred.df$c.greater.mcrs[i] <- sum(wt[pred.df$Mean.CL[i], cl.mids >= 20])
  pred.df$c.greater.mcrs[i] <- round(pred.df$c.greater.mcrs[i], 2)
  pred.df$total.catch[i] <- sum(wt[pred.df$Mean.CL[i], ])
  pred.df$total.catch[i] <- round(pred.df$total.catch[i], 2)
  ## value
  pred.df$v.less.mcrs[i] <- sum(value[pred.df$Mean.CL[i], cl.mids < 20])
  pred.df$v.less.mcrs[i] <- round(pred.df$v.less.mcrs[i], 2)
  pred.df$v.greater.mcrs[i] <- sum(value[pred.df$Mean.CL[i], cl.mids >= 20])
  pred.df$v.greater.mcrs[i] <- round(pred.df$v.greater.mcrs[i], 2)
  pred.df$total.value[i] <- sum(value[pred.df$Mean.CL[i], ])  
  pred.df$total.value[i] <- round(pred.df$total.value[i], 2)
}

@ 

\begin{landscape}
<<xtable, results="asis">>=
library(xtable)
print(xtable(pred.df, digits = 2, align = "lccccccccc"), include.rownames = FALSE)
@ 
\end{landscape}

\bibliography{../../../../misc/epif_bibliography}
\bibliographystyle{../../../../misc/cjfas}
\end{document}


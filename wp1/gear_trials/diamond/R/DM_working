##Attempting a comparison of MGLM with the Homemade Dirichlet functions

##First create some data
##This function was created to generate a dataframe for using MGLM
df.func<-function(x){
  Y1 <<- cbind(rep(100, x), rep(20, x), rep(80, x), rep(40, x))
  offset.mat <<- cbind(rep(0.125, x), rep(0.25, x), rep(0.1, x), rep(0.5, x))
  
  x1 <<- rnorm(nrow(Y1))
  x2 <<- rnorm(nrow(Y1))
  x3 <<- x2^2
  X <<- cbind(1, x1, x2, x3)
}

df.func(30)
df<-data.frame(Y1, x1, x2, x3)
names(df)<-c("Y1", "Y2", "Y3", "Y4", "x1", "x2", "x3")

##Setting up the MGLM regression
library(MGLM)

resp<-with(df, cbind(Y1,Y2,Y3,Y4))
DM.fit <- MGLMreg(resp ~ x2 + x3, dist="DM", data=df)
DM.fit

##This is the alpha for the MGLMreg function
DM.fit$fitted

##Compare to the Homemade DM functions - No offset in these functions
##The original DM func written by Cóilín were used, 
##The alternative DM functions written by Brian don't work unless as 
##the factorial function continuously to goes out of bounds 

##load DM func from the source file or load them from the code at the bottom of this R file
source("C:/Users/bburke/Documents/GitHub/epif/wp1/gear_trials/diamond/R/multi_funs.R")

npar <- ncol(Y1) *  ncol(X)
start.par <- rep(0, npar)

##This optim uses the method = BFGS, and produces an very small alpha
fit2 <- optim(par = start.par, fn = dm.nll, Y = Y1, X = X, control = list(trace = 2, reltol=1e-16, abstol=1e-16), method = "BFGS")

beta <- matrix(fit2$par, ncol = ncol(Y1))
eta <- X %*% beta
(p.fit2 <- exp(eta)/rowSums(exp(eta)))


###########################################################################
##This optim uses the method - L-BFGS-B and produces an alpha 
##very close to the MGLM alpha
fit3 <- optim(par = start.par, fn = dm.nll, Y = Y1, X = X, control = list(trace = 2, factr=1e7), method = "L-BFGS-B")

beta <- matrix(fit3$par, ncol = ncol(Y1))
eta <- X %*% beta
(p.fit3 <- exp(eta)/rowSums(exp(eta)))
###########################################################################

fit4 <- optim(par = start.par, fn = dm.nll.o, Y = Y1, X = X, off=offset.mat, control = list(trace = 2, factr=1e7), method = "L-BFGS-B")

beta <- matrix(fit4$par, ncol = ncol(Y1))
eta <- X %*% beta
(p.fit4 <- exp(eta)/rowSums(exp(eta)))


fit5 <- optim(par = start.par, fn = dm.nll.o, Y = Y1, X = X, off=offset.mat, control = list(trace = 2, factr=1e7), method = "Nelder-Mead")

beta <- matrix(fit5$par, ncol = ncol(Y1))
eta <- X %*% beta
(p.fit5 <- exp(eta)/rowSums(exp(eta)))

p.fit4 %in% p.fit5
##The different optim methods don't seem to change the alpha output

##Getting the alpha for the MGLM can be done in two ways
##The easy way
DM.fit$fitted

##The other way
beta.mglm <- matrix(DM.fit$coefficients, ncol = ncol(Y1))
eta.mglm <- X %*% beta.mglm
(p.mglm <- exp(eta.mglm)/rowSums(exp(eta.mglm)))

##Compare alpha's!
p
p.mglm
##Very different - our function is calculation very small values for all fittings
##I have no idea if a box constrainted optimisation will work with what I'm seeing

##Investigating the MGLM code on GitHub I found that
col1<-Y1[,1]/rowSums(Y1)
col2<-Y1[,2]/rowSums(Y1)
col3<-Y1[,3]/rowSums(Y1)
col4<-Y1[,4]/rowSums(Y1)
(fitted.mglm <- cbind(col1, col2, col3, col4))
##The observation for each Y divided by the total Y for that observation is the alpha 


##From reviewing the MGLM code I've noticed that the negative log likelihood function in 
##our homemade DM functions and in the MGLM package look quite different.
##https://github.com/cran/MGLM/blob/master/R/MGLMreg.R#L553

##Below is the code for the MGLM code on github and how they calculate there negative log likelihood
##These are defined earlier in the MGLM code: line 66-69
N <- nrow(Y1)
d <- ncol(Y1)
p <- ncol(X)

##MGLM negative log likelihood function from MGLM code: line 553-565
objfun <- function(alpha, x, y, d, p){
  alpha <- matrix(alpha, p, d)
  alpha <- exp(x%*%alpha)
  m <- rowSums(y)
  
  logl <- rowSums(lgamma(y+alpha)-lgamma(alpha))+
          lgamma(rowSums(alpha))-lgamma(rowSums(alpha)+m)+
          lgamma(m+1)-rowSums(lgamma(y+1)) 
  
  return(-sum(logl))
}

##I don't know how exactly but I think whatever calculation for the alpha
##the MGLM is doing could be getting messed up in the optimisation

######Checking the likelihood function
##Here I used the simple calculation for alpha and used both the dm.nll 
##function and the log likelihood function in the MGLM code 

beta <- matrix(start.par, ncol = ncol(Y1))
eta <- X %*% beta
alpha <- exp(eta)

-sum(rowSums(lgamma(Y1+alpha)-lgamma(alpha))+
     lgamma(rowSums(alpha))-lgamma(rowSums(alpha)+rowSums(Y1))+
     lgamma(rowSums(Y1)+1)-rowSums(lgamma(Y1+1)))


(nll <- - sum(sapply(1:nrow(Y1), function(z){
  ddm(n = Y1[z,], alpha = alpha[z,], log = TRUE)
})))

##whether you use the alpha we calculate or the alpha from MGLM
##each function calculates the same log likelihoods
##Why the alpha's are being calculated incorrectly doesn't appear obvious to me

###########################################################################################################################
##########################Dirichlet Multinomial Function###################################################################
ddm <- function(n, alpha, log = FALSE){
  ## calculates pdf on log-scale
  ## to deal with large numbers
  ## http://www2.math.su.se/matstat/reports/seriec/2014/rep6/report.pdf
  N <- sum(n)
  lpdf <- lfactorial(N) - sum(lfactorial(n)) + lgamma(sum(alpha)) - lgamma(sum(alpha + n)) + sum(lgamma(alpha + n) - lgamma(alpha))
  pdf <- exp(lpdf)
  if(log){
    return(lpdf)
  }else{
    return(pdf)
  }
}

dm.nll <- function(theta, Y, X){
  ## note using ddm not ddm2
  npar <- ncol(Y) *  ncol(X)
  if(length(theta) != npar){
    stop("Number of parameters supplied incorrect")
  }
  ##
  beta <- matrix(theta, ncol = ncol(Y))
  ## linear predictor
  eta <- X %*% beta ##+ log(off)
  print(eta)
  ## alphas
  alpha <- exp(eta) ## see http://www2.math.su.se/matstat/reports/seriec/2014/rep6/report.pdf
  ## log-likelihood
  ## note doing this because ddm works on a vector not a matrix
  nll <- - sum(sapply(1:nrow(Y), function(z){
    ddm(n = Y[z,], alpha = alpha[z,], log = TRUE)
  }))
  ##print(nll)
  return(nll)
}

dm.nll.o <- function(theta, Y, X, off){
  ## note using ddm not ddm2
  npar <- ncol(Y) *  ncol(X)
  if(length(theta) != npar){
    stop("Number of parameters supplied incorrect")
  }
  ##
  beta <- matrix(theta, ncol = ncol(Y))
  ## linear predictor
  eta <- X %*% beta + log(off)
  ## alphas
  alpha <- exp(eta) ## see http://www2.math.su.se/matstat/reports/seriec/2014/rep6/report.pdf
  ## log-likelihood
  ## note doing this because ddm works on a vector not a matrix
  nll <- - sum(sapply(1:nrow(Y), function(z){
    ddm(n = Y[z,], alpha = alpha[z,], log = TRUE)
  }))
  ##print(nll)
  return(nll)
}
